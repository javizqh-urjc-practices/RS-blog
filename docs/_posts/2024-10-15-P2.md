---
title: "P2: Rescue People"
date: 2024-10-15 18:00:00 +0100
tags: [weekly progress]     # TAG names should always be lowercase
author: javier
img_path: /assets/img/
toc: true
comments: true
pin: true
---

## Getting the relative coordinates of the survivors

We are given the coordinates of both the boat and the survivors in degrees, minutes and seconds:

* Boat (Start): 40º16’48.2” N, 3º49’03.5” W
* Survivors (Start Search): 40º16’47.23” N, 3º49’01.78” W

As the drone returns the position with the values 0m 0m at the start we just need to calculate the difference between both coordinates.

To do that first we convert those values into UTM to get the distance in meters and the result is:

* Boat (Start): 30N 430492mE 4459162mN
* Survivors (Start Search): 30N 430532mE 4459132mN

As the zone value is the same (30N) the operations needed are much simpler.

```math
east = 430532 - 430492 = 40
```

```math
north = 4459132 - 4459162 = -30
```

So the coordinates in our metric space of the survivors is -30, 40. And using trial and error to get the correct position of these 2 numbers we get the final value: (40, -30)

Also the angle the drone has to used while going to the destination would be: -0.64 rad. And when going back to the start it would be: 2.5 rad

## Moving in a cricles to cover the area

In order to search through the are efficiently I chose to do circles around the known survivors location as represented in the image below.

![Path Planning](rescue_people_move.svg)

The radius is increased by 2 meters to have an optimal search path.

As this circular path is generated beforehand when the drone starts to follow it the way to control it is by using set_cmd_pos to the next target in the path.  

## Detection of survivors

In order to detect the survivors I follow the next steps:

1. Apply a mask to only get a circular view of the image in order to simplify the position of the survivor. With this method I can asume that the position of the survivor is the one of the drone. The mask does not delete any useful data because as the circles are done with a 2 meter radius the drone goes to the part of the image that is covered by the mask. 

![Img filter](rescue_people_img.svg)

2. In order to detect the face properly it needs to be in the correct orientation. To solve this I rotate the image 20º each time and apply the haar algorithym to search for faces
3. If a face is detected it checks if there was already a survivor 3 meters around the current drone position. If there was not one, the survivor gets added to the list at the drone coordenates.

### Problems

While doing the face detection I faced multiple problems such as:

* If I equalized the image faces were detected in the sea
* It was necessary to call the detectMultiScale function with the next parameters to avoid detecting parts of the body of the survivors as faces:

```python
face_cascade.detectMultiScale(rot_img, scaleFactor=1.1, minSize =(20, 20), maxSize=(50,50) , minNeighbors=5)
```

## Videos
